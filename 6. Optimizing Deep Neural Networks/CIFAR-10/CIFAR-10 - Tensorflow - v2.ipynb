{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Hyperparameter & Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate, Iterations, Batch Size Hyperparameters\n",
    "learning_rate = 0.001\n",
    "iterations = 20000\n",
    "batch_size = 256\n",
    "#dropout = 0.5\n",
    "#epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR-10 Dataset has 60000 images of common objects, 6k images per class and 10 classes in total\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Convert to float type\n",
    "X_train, X_test = np.array(X_train, np.float32), np.array(X_test, np.float32)\n",
    "\n",
    "#Flatten images to 1-D vector of 3072 features (32*32*3)\n",
    "X_train, X_test = X_train.reshape([-1, 3072]), X_test.reshape([-1, 3072])\n",
    "\n",
    "#One hot encoding of labels\n",
    "Y_train = to_categorical(Y_train, 10)\n",
    "Y_test = to_categorical(Y_test, 10)\n",
    "\n",
    "#Normalization of images\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "#Use Tensorflow data for shuffling and fetching it batchwise\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(Model):\n",
    "    \n",
    "    def __init__(self, use_dp = True):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.use_dp = use_dp        \n",
    "        self.L1 = layers.Dense(3072, activation = tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.L2 = layers.Dense(2048, activation = tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.L3 = layers.Dense(1024, activation = tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.L4 = layers.Dense(512, activation = tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.L5 = layers.Dense(256, activation = tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.L6 = layers.Dense(128, activation = tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        if self.use_dp:\n",
    "            self.dp = layers.Dropout(0.5)\n",
    "        self.Yhat = layers.Dense(10)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False, use_dp = True):\n",
    "        x = self.L1(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp(x)\n",
    "        x = self.L2(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp(x)\n",
    "        x = self.L3(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp(x)\n",
    "        x = self.L4(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp(x)\n",
    "        x = self.L5(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp(x)\n",
    "        x = self.L6(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp(x)\n",
    "        x = self.Yhat(x)\n",
    "        if not is_training:\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build the network\n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost function definition, using the softmax cross entropy loss\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y_true)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics to check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To verify the predictions\n",
    "def accuracy(y_pred, y_true):\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    a = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the optimizer function with learning rate as parameter\n",
    "optimizer = tf.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all together (Optimization of the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(X, Y):\n",
    "    \n",
    "    #Using GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(X, is_training = True, use_dp = True)\n",
    "        loss = cross_entropy(pred, Y)\n",
    "        \n",
    "    #Get W and B values \n",
    "    train_variables = model.trainable_variables\n",
    "    \n",
    "    #Compute gradients.\n",
    "    gradients = tape.gradient(loss, train_variables)\n",
    "    \n",
    "    #Update W and b following gradients\n",
    "    optimizer.apply_gradients(zip(gradients, train_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train for 40000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pranav\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1000\n",
      "Loss = 1.3725861310958862\n",
      "Accuracy = 0.5078125\n",
      "\n",
      "Iteration = 2000\n",
      "Loss = 1.3023344278335571\n",
      "Accuracy = 0.515625\n",
      "\n",
      "Iteration = 3000\n",
      "Loss = 0.9607739448547363\n",
      "Accuracy = 0.64453125\n",
      "\n",
      "Iteration = 4000\n",
      "Loss = 0.7955528497695923\n",
      "Accuracy = 0.73046875\n",
      "\n",
      "Iteration = 5000\n",
      "Loss = 0.5276813507080078\n",
      "Accuracy = 0.8203125\n",
      "\n",
      "Iteration = 6000\n",
      "Loss = 0.3398495316505432\n",
      "Accuracy = 0.87890625\n",
      "\n",
      "Iteration = 7000\n",
      "Loss = 0.19062215089797974\n",
      "Accuracy = 0.9609375\n",
      "\n",
      "Iteration = 8000\n",
      "Loss = 0.07492822408676147\n",
      "Accuracy = 0.9765625\n",
      "\n",
      "Iteration = 9000\n",
      "Loss = 0.09678030759096146\n",
      "Accuracy = 0.98046875\n",
      "\n",
      "Iteration = 10000\n",
      "Loss = 0.04686673730611801\n",
      "Accuracy = 0.984375\n",
      "\n",
      "Iteration = 11000\n",
      "Loss = 0.054417334496974945\n",
      "Accuracy = 0.98046875\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a493f20355f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatch_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Run the optimization to update W and b values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-d2ecc0c21845>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Compute gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#Update W and b following gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_SoftmaxCrossEntropyWithLogitsGrad\u001b[1;34m(op, grad_loss, grad_grad)\u001b[0m\n\u001b[0;32m    534\u001b[0m         axis=1)) * softmax)\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BroadcastMul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(logits, axis, name, dim)\u001b[0m\n\u001b[0;32m   3120\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3121\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3122\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_softmax\u001b[1;34m(logits, compute_op, dim, name)\u001b[0m\n\u001b[0;32m   2983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2984\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_last_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2985\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcompute_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2987\u001b[0m   \u001b[0mdim_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(logits, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m   5138\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LogSoftmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m         tld.op_callbacks, logits)\n\u001b[0m\u001b[0;32m   5140\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Run the for-loop for a well defined number of epochs\n",
    "s = time.clock()\n",
    "loss_plot = []\n",
    "accuracy_plot = []\n",
    "\n",
    "for i, (Batch_x, Batch_y) in enumerate(train_data.take(20001), 1):\n",
    "    #Run the optimization to update W and b values.\n",
    "    run(Batch_x, Batch_y)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        pred = model(Batch_x, is_training = True, use_dp = False)\n",
    "        loss = cross_entropy(pred, Batch_y)\n",
    "        acc = accuracy(pred, Batch_y)\n",
    "        print('Iteration = {}'.format(i))\n",
    "        print('Loss = {}'.format(loss))\n",
    "        print('Accuracy = {}\\n'.format(acc))\n",
    "        \n",
    "        loss_plot.append(loss)\n",
    "        accuracy_plot.append(acc)\n",
    "        \n",
    "e = time.clock()\n",
    "\n",
    "print('Time Elapsed = {} \\n'.format(e-s))\n",
    "\n",
    "pred = model(X_test, is_training = False, use_dp = False)\n",
    "test_accuracy = accuracy(pred, Y_test)\n",
    "print('Accuracy on Test Set is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "iterations = np.arange(1000, 20001, 1000)\n",
    "plt.plot(iterations, loss_plot, label = 'Training Loss')\n",
    "plt.title('Loss graph')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(1000, 20001, 1000))\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = np.arange(1000, 20001, 1000)\n",
    "plt.plot(iterations, accuracy_plot, label = 'Training Accuracy')\n",
    "plt.title('Accuracy graph')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(1000, 20001, 1000))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Time Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time(index):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "    \n",
    "    prediction = model(X_test[index].reshape(1, 3072), is_training = False, use_dp = False)\n",
    "    print('Actual Ground Truth is {} ; {}'.format(np.squeeze(Y_test[index]), labels[np.argmax(Y_test[index])]))\n",
    "    print('Prediction for test image is {}; {}'.format(np.squeeze(prediction), labels[np.argmax(prediction[0])]))\n",
    "    plt.imshow(np.reshape(X_test[index].reshape(1, 3072), [32, 32, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
